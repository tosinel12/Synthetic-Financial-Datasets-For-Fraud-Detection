{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models and utility functions\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import average_precision_score, recall_score, precision_recall_curve\n",
    "from time import time\n",
    "import xgboost as xgb\n",
    "\n",
    "# ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# import data\n",
    "file = 'D:/python/fraud.csv'\n",
    "df = pd.read_csv(file)\n",
    "print(df.columns)\n",
    "df = df.rename(columns={'oldbalanceOrg': 'Old_Balance_Orig',\n",
    "                        'newbalanceOrig': 'New_Balance_Orig',\n",
    "                        'oldbalanceDest': 'Old_Balance_Dest',\n",
    "                        'newbalanceDest': 'New_Balance_Dest',\n",
    "                        'nameOrig': 'Name_Orig',\n",
    "                        'nameDest': 'Name_Dest'})\n",
    "\n",
    "\n",
    "#clean illogical data\n",
    "# prepared dataset\n",
    "df['day'] =pd.cut(df['step'],[0,24,48,72,96,120,144,168,192,216,240,264,288,312,336,360,384,408,432,456,480,504,528,552,576,600,624,648,672,\n",
    "                      696,720,744], labels=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31])\n",
    "\n",
    "df['day'] = df['day'].astype(int)\n",
    "df['Error_Orig']=df['Old_Balance_Orig']-df['New_Balance_Orig']-df['amount']\n",
    "df['Error_Dest']=df['Old_Balance_Dest']-df['New_Balance_Dest']+df['amount']\n",
    "print(df.head())\n",
    "\n",
    "# data import and cleaning\n",
    "df=df.drop(['step','isFlaggedFraud'], axis=1)\n",
    "sns.heatmap(df.corr())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(df.shape)\n",
    "print(df.loc[(df.isFraud==1)& (df.Old_Balance_Orig<df.amount)].shape)\n",
    "#print(df.loc[(df.isFraud==1)& (df.Old_Balance_Orig<df.amount)].index)\n",
    "df = df.drop(df.loc[(df.isFraud==1)& (df.Old_Balance_Orig<df.amount)].index) # 29\n",
    "\n",
    "df = df.drop(df.loc[(df.isFraud==1)& (df.amount==0)].index) # 16\n",
    "#print(df.shape,a.shape,b.shape,df.shape[0]-a.shape[0]-b.shape[0] )\n",
    "\n",
    "# confirm\n",
    "print('\\n The fraud case with amount equals to zero{}'. format(\n",
    "    len(df.loc[(df.isFraud==1) & (df.amount==0)])))\n",
    "\n",
    "\n",
    "print('\\n The types of fraudulent transactions are {}'.format(\n",
    "    list(df.loc[df.isFraud == 1].type.drop_duplicates().values)))\n",
    "#\n",
    "dfFraudTransfer = df.loc[(df.isFraud == 1) & (df.type == 'TRANSFER')]\n",
    "dfFraudCashout = df.loc[(df.isFraud == 1) & (df.type == 'CASH_OUT')]\n",
    "\n",
    "print('\\n No.fraudulent in TRANSFERs = {}'.\n",
    "      format(len(dfFraudTransfer)))\n",
    " # origin fraud in transfer is 4097\n",
    "\n",
    "print('\\n No.fraudulent in CASH_OUTs = {}'. \n",
    "      format(len(dfFraudCashout)))\n",
    "#origin fraud in cashout is 4116\n",
    "\n",
    "\n",
    "\n",
    "X = df.loc[(df.type == 'CASH_OUT')]\n",
    "X['Error_Orig']=X['Old_Balance_Orig']-X['New_Balance_Orig']-X['amount']\n",
    "X['Error_Dest']=X['Old_Balance_Dest']-X['New_Balance_Dest']+X['amount']\n",
    "y = X['isFraud']\n",
    "del X['isFraud']\n",
    "\n",
    "print(df.describe())\n",
    "\n",
    "\n",
    "#EDA\n",
    "\n",
    "X.hist(figsize=(20,20))\n",
    "plt.show()\n",
    "y.hist(figsize=(20,20))\n",
    "plt.show()\n",
    "\n",
    "# Eliminate columns shown to be irrelevant for analysis in the EDA\n",
    "X = X.drop(['Name_Orig', 'Name_Dest', 'type'], axis=1)\n",
    "print(X.head())\n",
    "print(X.info())\n",
    "\n",
    "print('\\nerror in the originates account history is {}'.format(len(X.loc[X.Error_Orig!=0])))\n",
    "\n",
    "print('\\nerror in the balance recipients history is {}'.format(len(X.loc[X.Error_Dest!=0])))\n",
    "\n",
    "print('\\nerror in both is {}'.format(len(X.loc[(X['Error_Orig']!=0) & (X['Error_Dest']!=0)])))\n",
    "\n",
    "print('\\nerror in both is {}'.format(len(X.loc[(X['Error_Orig']==0) & (X['Error_Dest']==0)])))\n",
    "\n",
    "print('\\n fraud without error in victim account is {}'.format(len(X.loc[(X['Error_Orig']==0) & (y==1)])))\n",
    "\n",
    "print('\\n OLD BALANCE PROBLEM in victim account is {}'.format(len(X.loc[(X['Old_Balance_Orig']<X['amount'])])))\n",
    "\n",
    "print('\\n OLD BALANCE PROBLEM in victim account is {}'.format(len(X.loc[(X['Old_Balance_Orig']==0) & (y==1)&(X['amount']==0)])))\n",
    "\n",
    "print('\\n OLD BALANCE PROBLEM in victim account is {}'.format(len(X.loc[(X['Old_Balance_Orig']<X['amount'])&(y==1)])))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# decision tree model\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#    X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# weight calculation\n",
    "weights = (y == 0).sum() / (1.0 * (y == 1).sum())\n",
    "\n",
    "# XGBoost\n",
    "clf = xgb.XGBClassifier(max_depth=3, scale_pos_weight=weights, n_jobs=4)\n",
    "probabilities = clf.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "# auprc equals to 0.7346\n",
    "y_pred=clf.predict(X_test)\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "print('accuracy of XGBoost result', acc)\n",
    "#acc is 0.96782122905\n",
    "print('AUPRC = {}'.format(\n",
    "    average_precision_score(y_test, probabilities[:, 1])))\n",
    "# recall score\n",
    "print('Recall:{0:2f}'.format(recall_score(y_test,y_pred)))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "# f1 score is good to evaluate unbalanced data\n",
    "print('F1 macro score')\n",
    "print(f1_score(y_test, y_pred, average='macro'))\n",
    "print('F1 micro score')\n",
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "\n",
    "\n",
    "# confusion matrix of decision tree result with .2 random test dataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('confusion matrix of decision tree with .2 random test data:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Cross validation accuracy score wiht cv = 5\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = xgb.XGBClassifier(max_depth=3, scale_pos_weight=weights, n_jobs=4)\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=7)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=kfold)\n",
    "#print('Cross validation confisuion matrix wiht cv = 5')\n",
    "#print([s for s in scores])\n",
    "\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (scores.mean()*100, scores.std()*100))\n",
    "\n",
    "\n",
    "\n",
    "# Cross validation confisuion matrix wiht cv = 5\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred = cross_val_predict(clf, X_train, y_train, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train, y_pred)\n",
    "print('Cross validation confisuion matrix wiht cv = 5')\n",
    "print(conf_mat)\n",
    "\n",
    "\n",
    "# Cross validation accuracy score wiht cv = 5\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = xgb.XGBClassifier(max_depth=3, scale_pos_weight=weights, n_jobs=4)\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=7)\n",
    "scores = cross_val_score(clf, X, y, cv=kfold)\n",
    "#print('Cross validation confisuion matrix wiht cv = 5')\n",
    "#print([s for s in scores])\n",
    "\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (scores.mean()*100, scores.std()*100))\n",
    "\n",
    "\n",
    "\n",
    "# Cross validation confisuion matrix wiht cv = 5\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_pred_all= cross_val_predict(clf, X, y, cv=kfold)\n",
    "conf_mat = confusion_matrix(y, y_pred_all)\n",
    "print('Cross validation confisuion matrix wiht cv = 5')\n",
    "print(conf_mat)\n",
    "\n",
    "# Plot precision recall curve\n",
    "y_scores = clf.predict_proba(X_test)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()\n"
   ]
  }
 ]
}
